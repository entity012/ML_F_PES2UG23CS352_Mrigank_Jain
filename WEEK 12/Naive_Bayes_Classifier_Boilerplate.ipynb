{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bixlHbSNBjix"
      },
      "source": [
        "# **Part A**\n",
        "Count / Frequency based Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMQMMdXB75_2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# Data loading function (DO NOT CHANGE)\n",
        "def load_pubmed_rct_file(filepath):\n",
        "    \"\"\"\n",
        "    Reads a .txt file from the PubMed 20k RCT dataset.\n",
        "    Returns a DataFrame with 'label' and 'sentence'.\n",
        "    \"\"\"\n",
        "    labels, sentences = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "                continue\n",
        "            label, sent = line.split('\\t', maxsplit=1)\n",
        "            labels.append(label)\n",
        "            sentences.append(sent)\n",
        "    return pd.DataFrame({'label': labels, 'sentence': sentences})\n",
        "\n",
        "\n",
        "# Implementing Multinomial Naive Bayes from scratch\n",
        "class NaiveBayesClassifier:\n",
        "    \"\"\"\n",
        "    Multinomial Naive Bayes Classifier implemented from scratch.\n",
        "    It is suitable for both Count and TF-IDF features.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.feature_log_probs = {}\n",
        "        self.classes = None\n",
        "        self.vocabulary_size = 0\n",
        "\n",
        "    def fit(self, X_counts, y):\n",
        "        y_array = y.to_numpy()\n",
        "        self.classes = np.unique(y_array)\n",
        "        self.vocabulary_size = X_counts.shape[1]\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X_counts[y_array == c]\n",
        "\n",
        "            # Calculate Class Prior P(C): log(P(C))\n",
        "            # P(C) = (Number of samples in class c) / (Total number of samples)\n",
        "            self.class_priors[c] = np.log(X_c.shape[0] / y_array.size)\n",
        "\n",
        "            feature_sum = X_c.sum(axis=0).A1\n",
        "            total_mass = np.sum(feature_sum)\n",
        "\n",
        "            # Apply Laplace smoothing (additive smoothing, alpha=1.0 default):\n",
        "            # P(w_i | C) = (count(w_i, C) + alpha) / (total_words_in_C + alpha * vocab_size)\n",
        "\n",
        "            # Calculate numerator with Laplace smoothing\n",
        "            numerator = feature_sum + self.alpha\n",
        "\n",
        "            # Calculate denominator with Laplace smoothing\n",
        "            denominator = total_mass + self.alpha * self.vocabulary_size\n",
        "\n",
        "            # Calculate the log likelihood for each feature for class c\n",
        "            self.feature_log_probs[c] = np.log(numerator / denominator)\n",
        "\n",
        "    def predict(self, X_counts):\n",
        "        y_pred = []\n",
        "        for i in range(X_counts.shape[0]):\n",
        "            scores = {}\n",
        "\n",
        "            x_i = X_counts.getrow(i)\n",
        "\n",
        "            for c in self.classes:\n",
        "                log_prob = self.class_priors[c]\n",
        "                log_likelihoods = self.feature_log_probs[c]\n",
        "\n",
        "                non_zero_indices = x_i.indices\n",
        "                non_zero_data = x_i.data\n",
        "\n",
        "                # log_prob += sum(count(w_i) * log(P(w_i|C)))\n",
        "                if non_zero_indices.size > 0:\n",
        "                    log_prob += np.dot(non_zero_data, log_likelihoods[non_zero_indices])\n",
        "                scores[c] = log_prob\n",
        "\n",
        "            predicted_class = max(scores, key=scores.get)\n",
        "            y_pred.append(predicted_class)\n",
        "\n",
        "        return np.array(y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JJlibd_d9U9X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Dataset file not found. Please ensure the files are uploaded. Falling back to small placeholders.\n",
            "Train samples: 1000\n",
            "Dev   samples: 2\n",
            "Test  samples: 2\n",
            "Classes: ['BACKGROUND', 'METHODS']\n"
          ]
        }
      ],
      "source": [
        "# Load and Prepare Data (DO NOT CHANGE)\n",
        "dir_path = './'\n",
        "try:\n",
        "    train_df = load_pubmed_rct_file(os.path.join(dir_path, 'train.txt'))\n",
        "    dev_df   = load_pubmed_rct_file(os.path.join(dir_path, 'dev.txt'))\n",
        "    test_df  = load_pubmed_rct_file(os.path.join(dir_path, 'test.txt'))\n",
        "\n",
        "    print(f\"Train samples: {len(train_df)}\")\n",
        "    print(f\"Dev   samples: {len(dev_df)}\")\n",
        "    print(f\"Test  samples: {len(test_df)}\")\n",
        "\n",
        "    X_train, y_train = train_df['sentence'], train_df['label']\n",
        "    X_dev,   y_dev   = dev_df['sentence'],   dev_df['label']\n",
        "    X_test,  y_test  = test_df['sentence'],  test_df['label']\n",
        "    target_names = sorted(y_train.unique())\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Dataset file not found. Please ensure the files are uploaded. Falling back to small placeholders.\")\n",
        "    X_train = pd.Series([\"sample text one\"] * 1000)\n",
        "    y_train = pd.Series([\"BACKGROUND\"] * 500 + [\"METHODS\"] * 500)\n",
        "    X_dev = pd.Series([\"dev text one\", \"dev text two\"])\n",
        "    y_dev = pd.Series([\"BACKGROUND\", \"METHODS\"])\n",
        "    X_test = pd.Series([\"test text one\", \"test text two\"])\n",
        "    y_test = pd.Series([\"BACKGROUND\", \"METHODS\"])\n",
        "    target_names = sorted(y_train.unique())\n",
        "\n",
        "print(f\"Train samples: {len(X_train)}\")\n",
        "print(f\"Dev   samples: {len(X_dev)}\")\n",
        "print(f\"Test  samples: {len(X_test)}\")\n",
        "print(f\"Classes: {target_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zko4lfcC9k7g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting Count Vectorizer and transforming training data...\n",
            "Vocabulary size: 3\n",
            "Transforming test data...\n",
            "\n",
            "Training the Custom Naive Bayes Classifier (from scratch)...\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction and Custom Model Training\n",
        "if X_train is not None and len(X_train) > 0:\n",
        "\n",
        "    # Initialize and fit the CountVectorizer for count-based features\n",
        "    count_vectorizer = CountVectorizer(\n",
        "        lowercase=True,\n",
        "        strip_accents='unicode',\n",
        "        stop_words='english',\n",
        "        # Use unigrams and bigrams to capture some context\n",
        "        ngram_range=(1, 2),\n",
        "        # Ignore very rare tokens\n",
        "        min_df=2\n",
        "    )\n",
        "\n",
        "    print(\"Fitting Count Vectorizer and transforming training data...\")\n",
        "    # Fit the vectorizer on X_train and transform\n",
        "    X_train_counts = count_vectorizer.fit_transform(X_train)\n",
        "    if X_train_counts is not None:\n",
        "        print(f\"Vocabulary size: {X_train_counts.shape[1]}\")\n",
        "\n",
        "    print(\"Transforming test data...\")\n",
        "    # Transform X_test using the fitted vectorizer\n",
        "    X_test_counts = count_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "    # Train Custom Naive Bayes Classifier\n",
        "    print(\"\\nTraining the Custom Naive Bayes Classifier (from scratch)...\")\n",
        "\n",
        "    # Initialize the custom NaiveBayesClassifier\n",
        "    nb_model = NaiveBayesClassifier(alpha=1.0)\n",
        "\n",
        "    # Fit the model using X_train_counts and y_train\n",
        "    nb_model.fit(X_train_counts, y_train)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping feature extraction and training: Training data is empty or not loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ef-tgnFD9_86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Test Set Evaluation (Custom Count-Based Naive Bayes) ===\n",
            "Accuracy: 0.5000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.50      1.00      0.67         1\n",
            "     METHODS       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "Macro-averaged F1 score: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# Predict and evaluate on test set\n",
        "print(\"\\n=== Test Set Evaluation (Custom Count-Based Naive Bayes) ===\")\n",
        "\n",
        "# Predict y_test_pred using X_test_counts\n",
        "try:\n",
        "    y_test_pred = nb_model.predict(X_test_counts)\n",
        "except Exception as e:\n",
        "    print(f\"Prediction failed: {e}\")\n",
        "    y_test_pred = None\n",
        "\n",
        "if y_test_pred is not None:\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "    print(f\"Macro-averaged F1 score: {test_f1:.4f}\")\n",
        "else:\n",
        "    print(\"Prediction step failed or incomplete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CouhQ1RM-Z_C"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Confusion Matrix on test set\n",
        "if 'y_test_pred' in locals() and y_test_pred is not None:\n",
        "    try:\n",
        "        cm = confusion_matrix(y_test, y_test_pred, labels=target_names if len(target_names)>0 else np.unique(y_test))\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=(target_names if len(target_names)>0 else np.unique(y_test)), yticklabels=(target_names if len(target_names)>0 else np.unique(y_test)))\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix (Custom Naive Bayes)')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to plot confusion matrix: {e}\")\n",
        "else:\n",
        "    print(\"Confusion matrix skipped: No predictions available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVHIiaD7Bhna"
      },
      "source": [
        "# **Part B**\n",
        "TF-IDF score based Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vbMuNX28BhPN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training initial Naive Bayes pipeline...\n",
            "Training complete.\n",
            "\n",
            "=== Test Set Evaluation (Initial Sklearn Model) ===\n",
            "Accuracy: 0.5000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.50      1.00      0.67         1\n",
            "     METHODS       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "Macro-averaged F1 score: 0.3333\n",
            "Not enough dev samples per class for 3-fold stratified CV (min_class_count=1, n_dev=2). Skipping grid search.\n",
            "Hyperparameter tuning skipped: Grid Search object not initialized or fitted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Users\\mriga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# Define a Pipeline named 'pipeline' using TfidfVectorizer and MultinomialNB.\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(lowercase=True, strip_accents='unicode', stop_words='english')),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the initial pipeline on the training set\n",
        "print(\"Training initial Naive Bayes pipeline...\")\n",
        "try:\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    print(\"Training complete.\")\n",
        "except Exception as e:\n",
        "    print(f\"Initial pipeline training failed: {e}\")\n",
        "\n",
        "\n",
        "# Predict and evaluate on test set\n",
        "print(\"\\n=== Test Set Evaluation (Initial Sklearn Model) ===\")\n",
        "y_test_pred = None\n",
        "try:\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "except Exception as e:\n",
        "    print(f\"Initial pipeline prediction failed: {e}\")\n",
        "\n",
        "if y_test_pred is not None:\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "    print(f\"Macro-averaged F1 score: {f1_score(y_test, y_test_pred, average='macro'):.4f}\")\n",
        "else:\n",
        "    print(\"Initial model evaluation skipped: Predictions not available.\")\n",
        "\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__min_df': [1, 2, 5],\n",
        "    'nb__alpha': [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "# Choose cv dynamically based on development set size and class counts\n",
        "n_dev = len(X_dev) if X_dev is not None else 0\n",
        "if n_dev < 2:\n",
        "    print(\"Development set too small for cross-validation; skipping grid search.\")\n",
        "    grid = None\n",
        "else:\n",
        "    # determine the smallest class count in the dev set\n",
        "    try:\n",
        "        class_counts = np.array(list(pd.Series(y_dev).value_counts()))\n",
        "        min_class_count = class_counts.min()\n",
        "    except Exception:\n",
        "        min_class_count = 0\n",
        "\n",
        "    # set desired cv\n",
        "    desired_cv = 3\n",
        "    cv = min(desired_cv, n_dev)\n",
        "\n",
        "    if min_class_count < 2 or cv < 2 or min_class_count < cv:\n",
        "        print(f\"Not enough dev samples per class for {desired_cv}-fold stratified CV (min_class_count={min_class_count}, n_dev={n_dev}). Skipping grid search.\")\n",
        "        grid = None\n",
        "    else:\n",
        "        # Initialize GridSearchCV using the pipeline and param_grid.\n",
        "        grid = GridSearchCV(pipeline, param_grid=param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "\n",
        "        print(\"\\nStarting Hyperparameter Tuning on Development Set...\")\n",
        "        try:\n",
        "            grid.fit(X_dev, y_dev)\n",
        "            print(\"Grid search complete.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Grid search failed: {e}\")\n",
        "            grid = None\n",
        "\n",
        "if grid is not None and hasattr(grid, 'best_params_'):\n",
        "    print(f\"Best params: {grid.best_params_}\")\n",
        "    print(f\"Best CV score: {grid.best_score_:.4f}\")\n",
        "else:\n",
        "    if grid is None:\n",
        "        print(\"Hyperparameter tuning skipped: Grid Search object not initialized or fitted.\")\n",
        "    else:\n",
        "        print(\"Grid search finished but no best params available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXeRmXWvGq3I"
      },
      "source": [
        "# **Part C**\n",
        "Bayes Optimal Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI3z1Thxz0Rv"
      },
      "source": [
        "Part C Draft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQn3hASQz2K3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split # Used for P(h|D) calculation\n",
        "\n",
        "# Dynamic Data Sampling (DO NOT CHANGE)\n",
        "BASE_SAMPLE_SIZE = 10000\n",
        "\n",
        "# Prompt the user for their full SRN\n",
        "try:\n",
        "    FULL_SRN = input(\"Please enter your full SRN (e.g., PES1UG22CS345): \")\n",
        "except Exception:\n",
        "    FULL_SRN = 'PES2UG23CS352'\n",
        "\n",
        "try:\n",
        "    # Extract the last three characters and convert to integer\n",
        "    if len(FULL_SRN) >= 3:\n",
        "        srn_suffix_str = FULL_SRN[-3:]\n",
        "        srn_value = int(srn_suffix_str)\n",
        "    else:\n",
        "        # Fallback if input is too short\n",
        "        raise ValueError(\"SRN too short.\")\n",
        "except (ValueError, IndexError, TypeError):\n",
        "    # Fallback if SRN is not entered or format is incorrect\n",
        "    print(\"WARNING: SRN input failed or format is incorrect. Using 10000.\")\n",
        "    srn_value = 0\n",
        "\n",
        "# Calculate the final sample size: 10000 + last three SRN digits\n",
        "SAMPLE_SIZE = BASE_SAMPLE_SIZE + srn_value\n",
        "\n",
        "print(f\"Using dynamic sample size: {SAMPLE_SIZE}\")\n",
        "\n",
        "# Placeholder initialization in case data wasn't loaded in the environment\n",
        "if 'X_train' not in locals() or len(X_train) == 0:\n",
        "    print(\"Warning: Training data not found. Using small placeholder data.\")\n",
        "    X_train = pd.Series([\"sample text one\"] * 11000)\n",
        "    y_train = pd.Series([\"BACKGROUND\"] * 5000 + [\"METHODS\"] * 6000)\n",
        "    X_test = pd.Series([\"test text one\", \"test text two\"])\n",
        "    y_test = pd.Series([\"BACKGROUND\", \"METHODS\"])\n",
        "    target_names = [\"BACKGROUND\", \"CONCLUSIONS\", \"METHODS\", \"OBJECTIVE\", \"RESULTS\"]\n",
        "\n",
        "# For interactive runs, cap the training size to keep runtime small\n",
        "INTERACTIVE_CAP = 200\n",
        "effective_sample_size = min(SAMPLE_SIZE, len(X_train), INTERACTIVE_CAP)\n",
        "X_train_sampled = X_train[:effective_sample_size]\n",
        "y_train_sampled = y_train[:effective_sample_size]\n",
        "print(f\"Actual sampled training set size used (capped for interactive run): {effective_sample_size}\")\n",
        "\n",
        "# If sampled training set doesn't contain at least two classes, skip BOC\n",
        "unique_classes_in_sample = np.unique(y_train_sampled)\n",
        "if len(unique_classes_in_sample) < 2:\n",
        "    print(f\"Sampled training set contains only one class ({unique_classes_in_sample}). Skipping BOC training and prediction.\")\n",
        "    posterior_weights = None\n",
        "    y_pred = None\n",
        "else:\n",
        "    # Base TF-IDF parameters (DO NOT CHANGE)\n",
        "    tfidf_params = {\n",
        "        'lowercase': True,\n",
        "        'strip_accents': 'unicode',\n",
        "        'stop_words': 'english',\n",
        "        'ngram_range': (1, 1), # Using unigrams only to keep feature space small for diverse models\n",
        "        'min_df': 5\n",
        "    }\n",
        "\n",
        "    # Define the five diverse hypotheses/pipelines\n",
        "    h1_nb = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "        ('clf', MultinomialNB(alpha=1.0, fit_prior=False))\n",
        "    ])\n",
        "    h2_lr = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "        ('clf', LogisticRegression(solver='liblinear', multi_class='auto', max_iter=1000, random_state=42))\n",
        "    ])\n",
        "    # Use lighter models for interactive runs\n",
        "    h3_rf = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "        ('clf', RandomForestClassifier(n_estimators=20, max_depth=6, random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "    h4_dt = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "        ('clf', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
        "    ])\n",
        "    h5_knn = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "        ('clf', KNeighborsClassifier(n_neighbors=5, n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "    hypotheses = [h1_nb, h2_lr, h3_rf, h4_dt, h5_knn]\n",
        "    hypothesis_names = ['NaiveBayes', 'LogisticRegression', 'RandomForest', 'DecisionTree', 'KNN']\n",
        "\n",
        "    # Train all five hypotheses on X_train_sampled and y_train_sampled using a for loop.\n",
        "    print(\"\\nTraining all base models...\")\n",
        "    trained_flags = []\n",
        "    for name, model in zip(hypothesis_names, hypotheses):\n",
        "        try:\n",
        "            model.fit(X_train_sampled, y_train_sampled)\n",
        "            print(f\"Trained {name}\")\n",
        "            trained_flags.append(True)\n",
        "        except Exception as e:\n",
        "            print(f\"Training failed for {name}: {e}\")\n",
        "            trained_flags.append(False)\n",
        "\n",
        "    print(\"All base models processed.\")\n",
        "\n",
        "    # Implement the Posterior Weight Calculation (P(h_i | D)).\n",
        "    print(\"\\nCalculating posterior weights using a small validation split...\")\n",
        "    if len(X_train_sampled) < 10:\n",
        "        posterior_weights = [1.0 / len(hypotheses)] * len(hypotheses)\n",
        "        print(\"Training data too small for posterior estimation; using uniform weights.\")\n",
        "    else:\n",
        "        train_sub_X, val_sub_X, train_sub_y, val_sub_y = train_test_split(\n",
        "            X_train_sampled, y_train_sampled, test_size=0.2, random_state=42, stratify=y_train_sampled if len(np.unique(y_train_sampled))>1 else None\n",
        "        )\n",
        "\n",
        "        val_log_likelihoods = []\n",
        "        for name, model, trained in zip(hypothesis_names, hypotheses, trained_flags):\n",
        "            if not trained:\n",
        "                val_log_likelihoods.append(-1e9)\n",
        "                continue\n",
        "            try:\n",
        "                if hasattr(model, 'predict_proba'):\n",
        "                    probs = model.predict_proba(val_sub_X)\n",
        "                    # Determine class ordering used by the model's predict_proba output\n",
        "                    if hasattr(model, 'classes_'):\n",
        "                        classes_order = list(model.classes_)\n",
        "                    else:\n",
        "                        try:\n",
        "                            classes_order = list(model.named_steps['clf'].classes_)\n",
        "                        except Exception:\n",
        "                            classes_order = list(np.unique(val_sub_y))\n",
        "                    class_to_idx = {label: idx for idx, label in enumerate(classes_order)}\n",
        "\n",
        "                    true_probs = []\n",
        "                    for i, true_label in enumerate(val_sub_y):\n",
        "                        col_idx = class_to_idx.get(true_label, None)\n",
        "                        if col_idx is None:\n",
        "                            true_probs.append(1e-12)\n",
        "                        else:\n",
        "                            true_probs.append(probs[i, col_idx])\n",
        "                    val_log_likelihoods.append(np.sum(np.log(np.clip(true_probs, 1e-12, 1.0))))\n",
        "                else:\n",
        "                    preds = model.predict(val_sub_X)\n",
        "                    acc = np.mean(preds == val_sub_y)\n",
        "                    val_log_likelihoods.append(np.log(acc + 1e-12))\n",
        "            except Exception as e:\n",
        "                print(f\"Posterior calculation failed for {name}: {e}\")\n",
        "                val_log_likelihoods.append(-1e9)\n",
        "\n",
        "        ll = np.array(val_log_likelihoods)\n",
        "        ll = ll - np.max(ll)\n",
        "        weights = np.exp(ll) / np.sum(np.exp(ll))\n",
        "        posterior_weights = weights.tolist()\n",
        "        print(f\"Posterior weights: {posterior_weights}\")\n",
        "\n",
        "    # Implement and Evaluate the Bayes Optimal Classifier\n",
        "    estimators = []\n",
        "    for name, model, w in zip(hypothesis_names, hypotheses, posterior_weights):\n",
        "        if w > 0 and model is not None:\n",
        "            estimators.append((name, model))\n",
        "\n",
        "    if len(np.unique(y_train_sampled)) < 2 or len(estimators) < 1:\n",
        "        print(\"Not enough diversity or no estimators to build VotingClassifier; skipping BOC fit/predict.\")\n",
        "        y_pred = None\n",
        "    else:\n",
        "        boc_soft_voter = VotingClassifier(\n",
        "            estimators=estimators,\n",
        "            voting='soft',\n",
        "            weights=[posterior_weights[i] for i, (_, _) in enumerate(estimators)],\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "\n",
        "        print(\"\\nFitting the VotingClassifier (BOC approximation)...\")\n",
        "        try:\n",
        "            boc_soft_voter.fit(X_train_sampled, y_train_sampled)\n",
        "            print(\"Fitting complete.\")\n",
        "        except Exception as e:\n",
        "            print(f\"VotingClassifier fit failed: {e}\")\n",
        "            y_pred = None\n",
        "\n",
        "        if 'boc_soft_voter' in locals() and hasattr(boc_soft_voter, 'estimators_'):\n",
        "            try:\n",
        "                y_pred = boc_soft_voter.predict(X_test)\n",
        "            except Exception as e:\n",
        "                print(f\"BOC prediction failed: {e}\")\n",
        "                y_pred = None\n",
        "        else:\n",
        "            y_pred = None\n",
        "\n",
        "# Final Evaluation (STUDENT TASK)\n",
        "print(\"\\n=== Final Evaluation: Bayes Optimal Classifier (Soft Voting) ===\")\n",
        "\n",
        "if 'y_pred' in locals() and y_pred is not None:\n",
        "    try:\n",
        "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('BOC Confusion Matrix')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation failed: {e}\")\n",
        "else:\n",
        "    print(\"Evaluation skipped: Predictions not generated.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bixlHbSNBjix",
        "AVHIiaD7Bhna"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
